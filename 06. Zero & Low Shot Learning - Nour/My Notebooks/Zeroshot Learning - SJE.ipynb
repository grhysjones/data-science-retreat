{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot learning for image classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original data and code can be found here https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/zero-shot-learning/zero-shot-learning-the-good-the-bad-and-the-ugly/)\n",
    "[Akata, et al. CVPR2015]\n",
    "[Xian, et al. CVPR2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download prepared data of Animal with attributes from: \n",
    "https://drive.google.com/open?id=1ErU12Q2sHhB2Lb7NCQuan0K3qXP78RJj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared data \n",
    "data_dict = np.load('/Users/garethjones/Downloads/data_dict.npz', encoding = 'latin1')['data'].item()\n",
    "\n",
    "tr_theta_x = data_dict['tr_theta_x'] # training image features extracted from deep CNN\n",
    "tr_labels = data_dict['tr_labels'] # training image labels as indices matching class embeddings and names\n",
    "val_theta_x = data_dict['val_theta_x']# validation image features extracted from deep CNN\n",
    "val_labels = data_dict['val_labels'] # validation image labels as indices matching class embeddings and names\n",
    "test_theta_x = data_dict['test_theta_x'] # test image features extracted from deep CNN\n",
    "test_labels = data_dict['test_labels'] # test image labels as indices matching class embeddings and names\n",
    "\n",
    "# class embeddings are a vector of features, in this case 85, for each class\n",
    "# this is the side knowledge, like we saw with polar bear example\n",
    "# when we compute weights of our model based on the training class embeddings, we'll be automatically able to link test images to the right vectors\n",
    "class_embeddings = data_dict['phi_y'] # class attributes vectors provided by the original dataset AWA. this is the side information\n",
    "class_names = data_dict['class_name'] # class names in the same order as embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antelope', 'grizzly+bear', 'killer+whale', 'persian+cat', 'german+shepherd', 'siamese+cat', 'skunk', 'tiger', 'hippopotamus', 'spider+monkey', 'humpback+whale', 'elephant', 'fox', 'squirrel', 'rhinoceros', 'wolf', 'chihuahua', 'weasel', 'otter', 'buffalo', 'zebra', 'pig', 'lion', 'mouse', 'polar+bear', 'collie', 'cow']\n",
      "['beaver', 'dalmatian', 'giant+panda', 'deer', 'mole', 'leopard', 'moose', 'raccoon', 'gorilla', 'ox', 'chimpanzee', 'hamster', 'rabbit']\n",
      "['rat', 'horse', 'blue+whale', 'bobcat', 'walrus', 'dolphin', 'sheep', 'seal', 'bat', 'giraffe']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# print training, validation, and test class names\n",
    "# note that class_embeddings and class_names \n",
    "\n",
    "# create classes dictionary\n",
    "class_dict = {}\n",
    "index = list(range(len(class_names)))\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    class_dict[index[i]] = class_names[i]\n",
    "class_dict\n",
    "\n",
    "# set quickly finds the unique values in a list\n",
    "unique_tr_labels = list(set(tr_labels))\n",
    "unique_val_labels = list(set(val_labels))\n",
    "unique_test_labels = list(set(test_labels))\n",
    "\n",
    "# list enumartion to find the unique names of labels\n",
    "tr_names = [class_dict[i] for i in unique_tr_labels]\n",
    "val_names = [class_dict[i] for i in unique_val_labels]\n",
    "test_names = [class_dict[i] for i in unique_test_labels]\n",
    "\n",
    "print(tr_names)\n",
    "print(val_names)\n",
    "print(test_names)\n",
    "print(len(tr_names)+len(val_names)+len(test_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(tr_theta_x,tr_labels,lr=0.0001,n_epochs=2,W=None):\n",
    "    \n",
    "    ####### use SGD to minimize SJE loss ######### \n",
    "    # Initialize W (DxE)\n",
    "    # foreach epoch \n",
    "        # Shuffle training samples\n",
    "        # foreach sample (xi, ytrue)\n",
    "            # 1. scoretrue =  ð›³(xi) * WT * ðœ™(ytrue)\n",
    "            # 2. lossmax= -1,  ymax = -1\n",
    "            # foreach training label ytr  \n",
    "                # 1. score =  ð›³(xi) * WT *ðœ™(ytr)\n",
    "                # 2. loss = Î”(ytr,ytrue) + scoretrue - score\n",
    "                # 3. if loss > lossmax --> update lossmax and ymax\n",
    "            # 4. if ymax â‰  ytrue --> W = W - lr * ð›³(xi) [ðœ™(ytrue) - ðœ™(ymax)]\n",
    "    \n",
    "    W = np.random.rand(tr_theta_x.shape[1],class_embeddings.shape[1])\n",
    "    \n",
    "    for e in range(n_epochs):\n",
    "        tr_labels = np.reshape(tr_labels,(len(tr_labels),1))\n",
    "        combined = np.append(tr_theta_x,tr_labels,axis=1)\n",
    "        np.random.shuffle(combined)\n",
    "        tr_theta_x_shuf = combined[:,:-1]\n",
    "        tr_labels_shuf = combined[:,-1]\n",
    "        \n",
    "        for i in range(len(tr_theta_x_shuf)):\n",
    "            phi_ytrue = class_embeddings[tr_labels[i],:]\n",
    "            scoretrue = np.dot(np.dot(tr_theta_x_shuf[i],W),phi_ytrue.T)\n",
    "            lossmax = -1\n",
    "            ymax = -1\n",
    "            \n",
    "            for j in list(set(map(int,tr_labels_shuf))):\n",
    "                phi_ytr = class_embeddings[j,:]\n",
    "                score = np.dot(np.dot(tr_theta_x_shuf[i],W),phi_ytr.T) \n",
    "                \n",
    "                if np.array_equal(phi_ytr,phi_ytrue) == True:\n",
    "                    loss = 0\n",
    "                else:\n",
    "                    loss = 1 + score - scoretrue\n",
    "                \n",
    "                if loss > lossmax:\n",
    "                        lossmax = loss\n",
    "                        ymax = j \n",
    "            \n",
    "            if ymax != tr_labels_shuf[i]:\n",
    "                phi_diff = phi_ytrue - class_embeddings[ymax,:]\n",
    "                # you need to do outer here to get the right shape to subtract\n",
    "                W = W - lr*np.outer(tr_theta_x_shuf[i],phi_diff) # second term is the gradient of our loss function\n",
    "                    \n",
    "    return W\n",
    "\n",
    "W = train(tr_theta_x,tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix shape is (2048, 85)\n",
      "Class Embeddings shape is (50, 85)\n",
      "Training features (theta) shape is (20218, 2048)\n",
      "Training labels (classes) shape is (20218, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Weight matrix shape is '+str(W.shape))\n",
    "print('Class Embeddings shape is '+str(class_embeddings.shape))\n",
    "print('Training features (theta) shape is '+str(tr_theta_x.shape))\n",
    "print('Training labels (classes) shape is '+str(tr_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "def predict(x,test_class_indices,W):\n",
    "    \n",
    "    # add your implementation\n",
    "    \n",
    "    #  max_score = -1,  ymax = -1\n",
    "    # foreach label in test_class_indices for i in test_class_indices: \n",
    "        # score =  ð›³(xi) * WT *ðœ™(label) \n",
    "        # if score > max_score --> update max_score and ymax\n",
    "    \n",
    "    max_score = -1\n",
    "    ymax = -1\n",
    "    \n",
    "    for i in list(set(map(int,test_class_indices))):\n",
    "        phi_label = class_embeddings[i,:]\n",
    "        score = np.dot(x,np.dot(W,phi_label.T))\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            ymax = i \n",
    "            \n",
    "    return ymax\n",
    "\n",
    "x = test_theta_x[1] # only ever input one image\n",
    "test_class_indices = list(set(test_labels)) # unique set\n",
    "\n",
    "ymax = predict(x,test_class_indices,W)\n",
    "print(ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039\n"
     ]
    }
   ],
   "source": [
    "def evaluate(X,Y,test_class_indices,W):\n",
    "\n",
    "    # correct_pred = 0\n",
    "    # foreach sample (xi, ytrue)\n",
    "        # pred_label = predict(xi,test_class_indices,W)\n",
    "        # if pred_label == ytrue:\n",
    "            # correct_pred += 1\n",
    "    # acc = correct_pred / size of test set\n",
    "    \n",
    "    correct_pred = 0\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        ytrue = Y[i]\n",
    "        pred_label = predict(X[i],test_class_indices,W)\n",
    "        if pred_label == ytrue:\n",
    "            correct_pred += 1\n",
    "    \n",
    "    acc = correct_pred / len(X)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "X = test_theta_x\n",
    "Y = test_labels\n",
    "test_class_indices = list(set(test_labels)) # unique set\n",
    "\n",
    "acc = '{:.3f}'.format(evaluate(X,Y,test_class_indices,W))\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
