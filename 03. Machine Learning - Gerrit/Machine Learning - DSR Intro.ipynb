{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "This notebook is supposed to be an introduction to Machine Learning with Python for DSRers, who may have no clue in ML, but know a little bit of Python.\n",
    "\n",
    "It's the first time this notebook is being used, mainly because:\n",
    "\n",
    "- Everything in one large notebook instead of several smaller ones.\n",
    "\n",
    "- To harmonize the content of the notebooks with the order of the slides.\n",
    "\n",
    "- Substantially extending on typical interview questions, which I think is the main result you will get from \"all the theory\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard settings I do\n",
    "plt.rcParams['savefig.dpi'] = 80\n",
    "\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['figure.figsize'] = 20, 12\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "\n",
    "plt.rcParams['text.usetex'] = False # True activates latex output in fonts!\n",
    "plt.rcParams['text.latex.preamble'] = \"\\\\usepackage{subdepth}, \\\\usepackage{type1cm}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are you going to learn? Well, mainly working with __scikit-learn__ and being able to use the models learned in the slides in a concrete implementation as well as judging your results (and assuring they are correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets \n",
    "\n",
    "We will start to work with the scikit learn datasets. There are three groups: `make` for synthetic, `load` for small datasets contained in sklearn, and `fetch` for (possibly larger) datasets that have to be downloaded once (they are usually stored in your user directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups, load_iris, make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_palette_to_cmap(palette):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    return ListedColormap(palette.as_hex())\n",
    "\n",
    "def get_cmap(n_classes):\n",
    "    return sns_palette_to_cmap(sns.hls_palette(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=200, n_features=2, centers=3, random_state=42)\n",
    "n_classes = len(np.unique(y))\n",
    "cmap = get_cmap(n_classes) # just to keep things standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap)\n",
    "plt.title(\"Three blobs in the plane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the first model we have discussed: k-NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(5)\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `score` one gets the metric the model was optimized for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"%.3f\" % (knn.score(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_surface(X, y, clf, n_classes=None):\n",
    "    \n",
    "    if n_classes is None:\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "    h = .02  # step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    colmap_light = sns_palette_to_cmap(sns.hls_palette(n_classes))\n",
    "    colmap_dark = sns_palette_to_cmap(sns.hls_palette(n_classes, l=.3, s=.6))\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=colmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=colmap_dark)\n",
    "    plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_surface(X, y, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise_: Build a k-NN classifier for this data set.\n",
    "Judge visually whether this will be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_gaussian_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_gaussian_quantiles(n_samples=200, n_classes=5, random_state=42)\n",
    "n_classes = len(np.unique(y))\n",
    "cmap = get_cmap(n_classes) # just to keep things standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features %s\" % boston.feature_names)\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = boston.data, boston.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(boston.data)\n",
    "df.columns = ['crime_rate','res_land_zoned','industry','charles_river','nox','avg_num_rooms','prop_bf_1940','dst_emply_center','rd_highway_idx','tax_rate','stdnt_tchr_ratio','prop_blacks','low_status_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares = LinearRegression(normalize=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=least_squares.coef_, y=df.columns, orient=\"h\")\n",
    "plt.title(\"Weights of least squares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how good is our model on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares.score(X, y) # R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `score` method always returns the metric the model has been optimized for. The `sklearn.metrics` package contains all kinds of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = least_squares.predict(X) # computes the predictions\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An unpleasant surprise\n",
    "\n",
    "But in reality our model has to form predictions on *unseen* data. Let's model this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score: %.4f\" % least_squares.score(X_train, y_train))\n",
    "print(\"Test score: %.4f\" % least_squares.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test score is way worse! This is the effect of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise*: Compute the MSE for the train and test set. How does it compare to the situation before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./solutions/mse.py\n",
    "y_pred_train = least_squares.predict(X_train)\n",
    "y_pred_test = least_squares.predict(X_test)\n",
    "\n",
    "print(\"Train MSE: %.4f\" % mean_squared_error(y_pred_train, y_train))\n",
    "print(\"Test MSE: %.4f\" % mean_squared_error(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models...\n",
    "\n",
    "Try other models, play with the parameters and try to beat the best score!\n",
    "\n",
    "*Extra*: Inspect the features not used by the Lasso model and remove them from the feature set. Does this improve the performance of all (others included!) models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge # L_2\n",
    "from sklearn.linear_model import Lasso # L_1\n",
    "from sklearn.linear_model import ElasticNet # convex(L_1, L_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=5e-2, normalize=True)\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score: %.4f\" % lasso.score(X_train, y_train))\n",
    "print(\"Test score: %.4f\" % lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = lasso.coef_ != 0.0\n",
    "print(used_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X[:, used_features]\n",
    "\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_reduced, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ must be lowered because there is less noise to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01, normalize=True)\n",
    "lasso.fit(X_train_red, y_train_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score: %.4f\" % lasso.score(X_train_red, y_train_red))\n",
    "print(\"Test score: %.4f\" % lasso.score(X_test_red, y_test_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipe = make_pipeline(\n",
    "    PolynomialFeatures(degree=5),\n",
    "    ElasticNet(alpha=0.001, \n",
    "               l1_ratio=0.3, \n",
    "               normalize=True, \n",
    "               random_state=42, \n",
    "               max_iter=1000)\n",
    ")\n",
    "\n",
    "clf_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_feats = PolynomialFeatures(degree=5)\n",
    "X_poly = poly_feats.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score: %.4f\" % clf_pipe.score(X_train, y_train))\n",
    "print(\"Test score: %.4f\" % clf_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, clf_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"polynomialfeatures__degree\": [1, 2, 3, 4, 5],\n",
    "    \"elasticnet__alpha\": [10**i for i in range(-2, 0)],\n",
    "    \"elasticnet__l1_ratio\": np.linspace(0.1, 0.9, 3)\n",
    "}\n",
    "\n",
    "clf_pipe = make_pipeline(\n",
    "    PolynomialFeatures(),\n",
    "    ElasticNet(normalize=True, random_state=42)\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(clf_pipe, params, scoring=\"r2\", verbose=True, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.cv_results_\n",
    "\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification\n",
    "\n",
    "## Preamble the data set\n",
    "\n",
    "We are using Fisher's famous <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">Iris data set</a>. The goal is to classify flowers from the Iris family into one of three species, that look as follows:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> <img src=\"figures/iris_setosa.jpg\" width=\"200\" style=\"height:150px\"/> </td>\n",
    "<td> <img src=\"figures/iris_versicolor.jpg\" width=\"200\" style=\"height:150px\"/> </td>\n",
    "<td> <img src=\"figures/iris_virginica.jpg\" width=\"200\" style=\"height:150px\"/> </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "<td>Iris Setosa</td>\n",
    "<td>Iris Versicolor</td>\n",
    "<td>Iris Virginica</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Our data set contains 50 flowers from each class, thus 150 in total. There are four features, the length and width of the petal (dt. Kronblatt) and sepal (dt. Kelchblatt) in centimetres.\n",
    "\n",
    "<img src=\"figures/petal_sepal.jpg\" width=\"400\" style=\"height:300px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is distributed with sci-kit learn, the only thing we have to do is to important a function and call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "\n",
    "print(\"First three rows of data\\n %s\" % X[:3])\n",
    "print(\"First three labels: %s\" % (y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Not only do we get the input matrix $X \\in \\mathbb{R}^{150 \\times 4}$ and target $y \\in \\mathbb{R}^{150}$, but also meta information such as what the class labels $0, 1, 2$ stand for and what the features (i.e. columns of $X$) correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.target_names)\n",
    "print(data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step we focus our analysis on the first two variables, the sepal length and sepal width. Since we obtain a representation of the data in two dimensions, we are able to plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X[:, :2]\n",
    "y_2 = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We write a function so we can reuse it later.\n",
    "def generate_scatter_plot(X, y):\n",
    "    class_names = data.target_names\n",
    "    class_colours = ['blue','yellow','green']\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6)) # increase size of plot\n",
    "    \n",
    "    for i, class_colour in enumerate(class_colours):\n",
    "        # plot the points only of this class label\n",
    "        plt.scatter(X[y == i, 0], X[y == i, 1], c=class_colour, label=class_names[i]) \n",
    "\n",
    "    plt.xlabel(data.feature_names[0]) # label the axis\n",
    "    plt.ylabel(data.feature_names[1])\n",
    "    plt.legend(loc=\"best\") # with legend\n",
    "\n",
    "generate_scatter_plot(X_2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "We do a \"setosa vs others\" classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "y_setosa = copy(y)\n",
    "y_setosa[(y == 2) | (y == 1)] = 0\n",
    "y_setosa[y == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_setosa, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1, penalty=\"l2\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train-Score: %.4f, Test-Accuracy: %.4f\" % (clf.score(X_train, y_train), clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification\n",
    "\n",
    "Now try the multi-class problem. Look up the slides for the multi-class logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class=\"multinomial\", \n",
    "                         penalty=\"l2\",\n",
    "                         random_state=42,\n",
    "                         solver=\"newton-cg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, \n",
    "                      clf.predict(X_test), \n",
    "                      #labels=data.feature_names,\n",
    "                      target_names=data.target_names\n",
    "                     )\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "The goal of this lab is to introduce you the most important techniques for evaluating your trained models. The motivation is to be able to select the model that has the best (expected) out-of-sample prediction and to assess the quality of the model.\n",
    "\n",
    "## 1. Model Selection in a holdout setting\n",
    "\n",
    "We start with the <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">Iris</a> data set. In a nut shell the iris data set consists out of $4$ features (sepal length, sepal width, petal length, petal width) of three kinds of flowers in the iris family (iris setosa, iris versicolor, iris virginica). It was first used by Fisher to introduce linear discriminant analysis. Our version of the data set has 150 data points with 50 for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "print(\"Loaded %d data points\" % len(iris.data))\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print(\"Class labels: %s\" % list(zip(range(3), iris.target_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first example we try to classify the iris versicolor with the help of the first two features (that makes visualisation simpler as we do not know PCA yet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_versi = X[:, :2]\n",
    "\n",
    "y_versi = np.zeros(len(y))\n",
    "y_versi[y == 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_versi[:, 0], X_versi[:, 1], c=y_versi, cmap=get_cmap(2), s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot shows that this is going to be a hard seperation problem as the classifier has to predict the red points. \n",
    "\n",
    "We split the data into a train and test (holdout) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_versi, y_versi, random_state=3)\n",
    "train_test_split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is a little visualization helper that draws the values of the decision function on a heat map given a matplotlib axe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_decision_function(clf, ax):\n",
    "    xx, yy = np.meshgrid(np.linspace(4.5, 8, 200), np.linspace(1.5, 4.0, 200))\n",
    "    try:\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    except AttributeError:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 0]\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.pcolormesh(xx, yy, Z, cmap=plt.cm.jet)\n",
    "    ax.set_xlim(4.5, 8)\n",
    "    ax.set_ylim(1.5, 4.0)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "show_decision_function(clf, ax)\n",
    "ax.set_title('Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn metrics package offers the basic evaluation routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Test Precision: %.3f\" % metrics.precision_score(y_test, y_pred))\n",
    "print(\"Test Recall: %.3f\" % metrics.recall_score(y_test, y_pred))\n",
    "print(\"Test F-Score: %.3f\" % metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling the definition of precision and recall the numbers mean that 2/3 of the positive predictions are correct and that 1/2 of the test iris versicolor has been found by the classifier. The F-Score is then just the arithmetic mean of both (7/12).\n",
    "\n",
    "To plot the ROC curve the decision function needs to be explicitly evaluated. The following code block also contains a helper function to plot ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.decision_function(X_test)\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_score, pos_label=1)\n",
    "\n",
    "\n",
    "# helper to plot ROC curves\n",
    "def plot_roc_curves(fprs, tprs):\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % metrics.auc(fpr, tpr))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curves([fpr], [tpr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ex. 1.1</b>: Train four different classifiers (on the train/test data we used in the prior example) and put them into the list 'clfs' (you can add elements to a list via the 'append' method. Analyse the visualisations that are created by the code blocks after (Is there a uniquely best classifier?). Set the $\\gamma$ parameter to $1$ and vary the $C$. Before trying out values be sure to check the <a href=\"http://scikit-learn.org/stable/modules/svm.html\">SVM</a> documentation in scikit-learn.\n",
    "\n",
    "Hint: Set a name to your classifier, i.e. clf.name = \"Some description\" to keep track of what you have done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.1\n",
    "from sklearn.svm import SVC\n",
    "clfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/eval_11.py\n",
    "# Solution Exercise 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code visualises the decision functions of the four different classifiers.\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "for clf, ax in zip(clfs, axes.ravel()):\n",
    "    show_decision_function(clf, ax)\n",
    "    ax.set_title(clf.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the roc curves.\n",
    "\n",
    "fprs, tprs = [], []\n",
    "\n",
    "for clf in clfs:\n",
    "    y_score = clf.decision_function(X_test)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_score, pos_label=1)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    \n",
    "plot_roc_curves(fprs, tprs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-Validation\n",
    "\n",
    "Having only 150 samples it seems like a waste to waste 30% of the training samples into the holdout set. To avoid this we can use CV - as presented in the lecture - to trade computational power for a better use of our data. \n",
    "\n",
    "The following code creates a list of masks, where every mask can be used as an index set to select the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kfold_mask(num_samples, k):\n",
    "    masks = []\n",
    "    fold_size = num_samples / k\n",
    "    \n",
    "    for i in range(k):\n",
    "        mask = np.zeros(num_samples, dtype=bool)\n",
    "        mask[i*fold_size:(i+1)*fold_size] = True\n",
    "        masks.append(mask)\n",
    "        \n",
    "    return masks\n",
    "\n",
    "masks = create_kfold_mask(150, 10)\n",
    "plt.matshow(masks)\n",
    "\n",
    "mask = masks[0]\n",
    "print(X_versi[mask]) # selects the test sample\n",
    "print(len(X_versi[~mask])) # selects training sample, ~ is binary negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is sorted by the labels the $k$-fold CV will likely have trouble with class imbalances in the some cases. A random shuffle solves this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_versi)\n",
    "num_sample = len(X_versi)\n",
    "np.random.seed(3)\n",
    "permutation = np.random.permutation(num_sample)\n",
    "X_versi, y_versi = X_versi[permutation], y_versi[permutation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ex. 2.1</b>: Implement the function scores = cv_k_fold_classifier(clf, k, X, y) that fits the classifier clf on the k-fold cvs of X and y. It returns two lists of scores: the training and test scores of each fold. Interpret the results of the code block after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.1\n",
    "\n",
    "def cv_k_fold_classifier(clf, k, X, y):\n",
    "    training_scores = []\n",
    "    test_scores = []\n",
    "        \n",
    "    # Your code\n",
    "\n",
    "    return training_scores, test_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Exercise 2.1\n",
    "\n",
    "def cv_k_fold_classifier(clf, k, X, y):\n",
    "    training_scores = []\n",
    "    test_scores = []\n",
    "   \n",
    "    # Your code\n",
    "    n = len(X)\n",
    "    masks = create_kfold_mask(n, k)\n",
    "    \n",
    "    for mask in masks:\n",
    "        X_train, y_train = X[~mask], y[~mask]\n",
    "        clf.fit(X_train, y_train)\n",
    "        training_scores.append(clf.score(X_train, y_train))\n",
    "        \n",
    "        X_test, y_test = X[mask], y[mask]\n",
    "        test_scores.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    return training_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with complete data now and use k-fold CV\n",
    "# still needs to shuffle data\n",
    "X_versi_2 = X[permutation]\n",
    "\n",
    "y_versi_2 = np.zeros(len(y))\n",
    "y_versi_2[y == 1] = 1\n",
    "y_versi_2 = y_versi_2[permutation]\n",
    "\n",
    "Cs = np.linspace(0.01, 10, 100)\n",
    "\n",
    "training_scores = []\n",
    "test_scores = []\n",
    "\n",
    "\n",
    "for C in Cs:\n",
    "    clf = SVC(C=C)\n",
    "    clf.name = \"SVM with C = {}\".format(C)\n",
    "    training_score, test_score = map(lambda xs: np.mean(xs), cv_k_fold_classifier(clf, 10, X_versi_2, y_versi_2))\n",
    "    training_scores.append(training_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(Cs, training_scores, label='Training Error')\n",
    "plt.plot(Cs, test_scores, label = 'Test Error')\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0.8, 1.00)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Error')\n",
    "plt.title('RBF SVM classification error of Iris versicolor on whole Iris data set')\n",
    "plt.legend()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn also contains procedures for creating CV. One of them is stratified k-fold CV, which is k-fold while ensuring that there is no local class imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cross_validation as cv\n",
    "\n",
    "# Helper to plot scikit CV\n",
    "\n",
    "def plot_cv(cv):\n",
    "    masks = []\n",
    "    for train, test in cv: # this shows you how to use the cv results!\n",
    "        # i.e. X_train, y_train = X[train], y[train]\n",
    "        mask = np.zeros(cv.n, dtype=bool)\n",
    "        mask[test] = 1\n",
    "        masks.append(mask)\n",
    "    \n",
    "    plt.matshow(masks)\n",
    "    \n",
    "kfold = cv.StratifiedKFold(y, n_folds=10) # using it on the original multi-class labels\n",
    "plot_cv(kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note how the folds partition into the regions of the three class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other CV methods do not require labels only the length of the labels\n",
    "plot_cv(cv.KFold(len(y), n_folds=10)) # like we implemented\n",
    "plot_cv(cv.ShuffleSplit(len(y), n_iter=10, test_size=0.3)) # like training_test_split with test 30% of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ex. 2.2</b>: Using the whole dataset build any classifier that detects iris virginica. \n",
    "Try two cross validation strategies:\n",
    "\n",
    "a) stratified 2-fold CV\n",
    "\n",
    "b) LOOCV (leave one out cross validation)\n",
    "\n",
    "Choose the best models in a) and b). Compare those two models, which one is likely to be better? What do the ROC curves tell you? Should an additional holdout set be used?\n",
    "\n",
    "Hint: The accuracy is the mean of the accuracy on every test set. In LOOCV this is the one test sample. Thus, the overall accuracy is equivalent to the ratio of folds in which the test sample was correctly predicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_clf = LogisticRegression(C=1, solver=\"saga\", multi_class=\"multinomial\")\n",
    "\n",
    "param = {\n",
    "    \"C\": [0.03, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    \"penalty\": (\"l1\", \"l2\")\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(base_clf, param, scoring=\"accuracy\", cv=ShuffleSplit(3), verbose=1)\n",
    "scores = cross_val_score(clf, X, y, scoring=\"accuracy\", cv=ShuffleSplit(5), n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"%.4f (Â±%.4f)\" % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)\n",
    "y_pred = clf.predict_proba(X)\n",
    "\n",
    "mask = y_pred >= 0.5\n",
    "y_pred[mask] = 1\n",
    "y_pred[~mask] = 0\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Exercise 2.2\n",
    "\n",
    "virgin_idx = y == 2\n",
    "y_virgin = np.zeros(len(y))\n",
    "y_virgin[virgin_idx] = 1\n",
    "\n",
    "from sklearn import grid_search\n",
    "from sklearn.cross_validation import LeaveOneOut, StratifiedKFold\n",
    "\n",
    "parameters = {\n",
    "    'kernel':('linear', 'rbf'), \n",
    "    'C':[0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "# a)\n",
    "clf = grid_search.GridSearchCV(svc, parameters, scoring='accuracy', cv=StratifiedKFold(y_virgin, 2))\n",
    "clf.fit(X, y_virgin) \n",
    "\n",
    "best_clf_a = clf.best_estimator_\n",
    "\n",
    "y_score = best_clf_a.decision_function(X)\n",
    "fpr_a, tpr_a, _ = metrics.roc_curve(y_virgin, y_score, pos_label=1)\n",
    "\n",
    "print(\"Best Classifier (2-fold): %s\" % best_clf_a)\n",
    "print(\"Best Accuracy (2-fold): %.4f\" % clf.best_score_)\n",
    "# b)\n",
    "clf = grid_search.GridSearchCV(svc, parameters, scoring='accuracy', cv=LeaveOneOut(150))\n",
    "clf.fit(X, y_virgin)   \n",
    "\n",
    "best_clf_b = clf.best_estimator_\n",
    "\n",
    "y_score = best_clf_b.decision_function(X)\n",
    "fpr_b, tpr_b, _ = metrics.roc_curve(y_virgin, y_score, pos_label=1)\n",
    "plot_roc_curves([fpr_a, fpr_b], [tpr_a, tpr_b])\n",
    "\n",
    "print(\"Best Classifier (LOOCV): %s\" % best_clf_b)\n",
    "print(\"Best Accuracy (LOOCV): %.4f\" % clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "param_range = np.logspace(-6, -1, 5)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    SVC(), X, y, param_name=\"gamma\", param_range=param_range,\n",
    "    cv=10, scoring=\"accuracy\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wrapping up: Politician recognition\n",
    "\n",
    "This section is optional and supposed to be a playground to try out things presented in the lectures so far. Running the next cell loads the data set that loads about 1300 images of politicians of the era of the war in Iraq. As this data set is about 200 MB this can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4,\n",
    "                                       data_home='datasets')\n",
    "print(\"Loaded %d data points with %d features\" % (lfw_people.data.shape[0], lfw_people.data.shape[1]))\n",
    "print(\"Names of politicians: %s\" % lfw_people.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots some images, feel free to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "# plot several images\n",
    "for i in range(15):\n",
    "    ax = fig.add_subplot(3, 5, i + 1, xticks=[], yticks=[]) # xticks / yticks = [] ensures no border\n",
    "    ax.imshow(lfw_people.images[i], cmap=plt.cm.bone)\n",
    "    ax.set_title(lfw_people.target_names[lfw_people.target[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ex. 3.1 (Optional)</b>: Train a classifier for the politician recognition problem. Ideally, you should solve the multiclass problem and use CV and scoring techniques. You can also train a binary classifier to detect one of the politicians.\n",
    "\n",
    "Show what you can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple train test split (can be used, but you can also do CV based approaches).\n",
    "X_train, X_test, y_train, y_test = train_test_split(lfw_people.data, lfw_people.target, random_state=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
